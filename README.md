# Data-Engineering-Project
This project is a data engineering pipeline built using Python, Apache Airflow, Docker, and Metabase. The pipeline is designed to extract, transform, and load (ETL) data from various sources into a central data repository.
The goal is to extract data from twitter and stock market. Make use of tweet sentiment analysis to compare stock price flunctuation.

## Requirements
* Docker
* Python 3.x
* Apache Airflow
* Metabase

## Usage
The pipeline consists of various tasks that extract data from sources, transform the data, and load it into the target data repository. The pipeline can be scheduled to run at specific intervals or manually triggered.

## Conclusion
This project demonstrates how to build a scalable and robust data engineering pipeline using the latest technologies such as Python, Apache Airflow, Docker, and Metabase. The pipeline can be easily customized and extended to meet the changing needs of the business.
